version: '3.8'

services:
  # API Gateway
  api-gateway:
    build:
      context: ./server
      dockerfile: ../docker/Dockerfiles/api-gateway.Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    ports:
      - "4000:4000"
    environment:
      - NODE_ENV=development
      - PORT=4000
      # Logging configuration
      - LOG_LEVEL=info
      - KAFKA_BROKERS=kafka:29092
      - KAFKA_LOGS_TOPIC=logs
      - LOG_CONSOLE=true
    volumes:
      - ./server/apps/api-gateway:/app/apps/api-gateway:delegated
      - ./server/libs:/app/libs:delegated
      - ./server/nest-cli.json:/app/nest-cli.json:delegated
      - ./server/tsconfig.json:/app/tsconfig.json:delegated
      - ./server/webpack-hmr.config.js:/app/webpack-hmr.config.js:delegated
      - api-gateway-node-modules:/app/node_modules
    depends_on:
      auth-service:
        condition: service_healthy
      user-service:
        condition: service_healthy
      chat-service:
        condition: service_healthy
      notification-service:
        condition: service_healthy
    networks:
      - chat-network
    profiles: [ "api", "all" ]
    healthcheck:
      test: [ "CMD", "wget", "--spider", "http://localhost:4000/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Auth Service
  auth-service:
    build:
      context: ./server
      dockerfile: ../docker/Dockerfiles/auth-service.Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    ports:
      - "4001:4001"
    environment:
      - NODE_ENV=development
      - PORT=4001
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/auth_db
    volumes:
      - ./server/apps/auth-service:/app/apps/auth-service:delegated
      - ./server/libs:/app/libs:delegated
      - ./server/nest-cli.json:/app/nest-cli.json:delegated
      - ./server/tsconfig.json:/app/tsconfig.json:delegated
      - ./server/webpack-hmr.config.js:/app/webpack-hmr.config.js:delegated
      - auth-service-node-modules:/app/node_modules
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - chat-network
    profiles: [ "auth", "all" ]
    healthcheck:
      test: [ "CMD", "wget", "--spider", "http://localhost:4001/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # User Service
  user-service:
    build:
      context: ./server
      dockerfile: ../docker/Dockerfiles/user-service.Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    ports:
      - "4002:4002"
    environment:
      - NODE_ENV=development
      - PORT=4002
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/user_db
    volumes:
      - ./server/apps/user-service:/app/apps/user-service:delegated
      - ./server/libs:/app/libs:delegated
      - ./server/nest-cli.json:/app/nest-cli.json:delegated
      - ./server/tsconfig.json:/app/tsconfig.json:delegated
      - ./server/webpack-hmr.config.js:/app/webpack-hmr.config.js:delegated
      - user-service-node-modules:/app/node_modules
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - chat-network
    profiles: [ "user", "all" ]
    healthcheck:
      test: [ "CMD", "wget", "--spider", "http://localhost:4002/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Chat Service
  chat-service:
    build:
      context: ./server
      dockerfile: ../docker/Dockerfiles/chat-service.Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    ports:
      - "4003:4003"
    environment:
      - NODE_ENV=development
      - PORT=4003
      - MONGODB_URI=mongodb://mongo:mongo@mongo:27017/chat_db?authSource=admin
    volumes:
      - ./server/apps/chat-service:/app/apps/chat-service:delegated
      - ./server/libs:/app/libs:delegated
      - ./server/nest-cli.json:/app/nest-cli.json:delegated
      - ./server/tsconfig.json:/app/tsconfig.json:delegated
      - ./server/webpack-hmr.config.js:/app/webpack-hmr.config.js:delegated
      - chat-service-node-modules:/app/node_modules
    depends_on:
      mongo:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - chat-network
    profiles: [ "chat", "all" ]
    healthcheck:
      test: [ "CMD", "wget", "--spider", "http://localhost:4003/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Notification Service
  notification-service:
    build:
      context: ./server
      dockerfile: ../docker/Dockerfiles/notification-service.Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    ports:
      - "4004:4004"
    environment:
      - NODE_ENV=development
      - PORT=4004
      - MONGODB_URI=mongodb://mongo:mongo@mongo:27017/notification_db?authSource=admin
    volumes:
      - ./server/apps/notification-service:/app/apps/notification-service:delegated
      - ./server/libs:/app/libs:delegated
      - ./server/nest-cli.json:/app/nest-cli.json:delegated
      - ./server/tsconfig.json:/app/tsconfig.json:delegated
      - ./server/webpack-hmr.config.js:/app/webpack-hmr.config.js:delegated
      - notification-service-node-modules:/app/node_modules
    depends_on:
      mongo:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - chat-network
    profiles: [ "notification", "all" ]
    healthcheck:
      test: [ "CMD", "wget", "--spider", "http://localhost:4004/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Logging Service
  logging-service:
    build:
      context: ./server
      dockerfile: ../docker/Dockerfiles/logging-service.Dockerfile
    ports:
      - "4005:4005"
    env_file:
      - ./docker/config/logging/logging-config.env
    environment:
      - NODE_ENV=development
      - PORT=4005
    volumes:
      - ./server/apps/logging-service:/app/apps/logging-service:delegated
      - ./server/libs:/app/libs:delegated
      - ./server/nest-cli.json:/app/nest-cli.json:delegated
      - ./server/tsconfig.json:/app/tsconfig.json:delegated
      - ./server/webpack-hmr.config.js:/app/webpack-hmr.config.js:delegated
      - logging-service-node-modules:/app/node_modules
    depends_on:
      kafka:
        condition: service_healthy
      loki:
        condition: service_healthy
    networks:
      - chat-network
    profiles: [ "logging", "all" ]
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4005/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  # PostgreSQL
  postgres:
    image: postgres:14-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./docker/init-scripts/postgres:/docker-entrypoint-initdb.d
    networks:
      - chat-network
    profiles: [ "db", "all", "auth", "user" ]
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  # MongoDB
  mongo:
    image: mongo:5
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=mongo
      - MONGO_INITDB_ROOT_PASSWORD=mongo
    volumes:
      - mongo-data:/data/db
      - ./docker/init-scripts/mongo:/docker-entrypoint-initdb.d
    networks:
      - chat-network
    profiles: [ "db", "all", "chat", "notification" ]
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  # Kafka
  zookeeper:
    image: bitnami/zookeeper:3.8
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    volumes:
      - zookeeper-data:/bitnami/zookeeper
    networks:
      - chat-network
    profiles: [ "kafka", "all", "auth", "user", "chat", "notification", "logging", "infra" ]
    healthcheck:
      test: [ "CMD-SHELL", "echo ruok | nc localhost 2181 || exit 0" ]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  kafka:
    image: bitnami/kafka:3.4
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      - KAFKA_BROKER_ID=2
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,PLAINTEXT_INTERNAL://:29092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT_INTERNAL
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_DELETE_TOPIC_ENABLE=true
    volumes:
      - kafka-data:/bitnami/kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - chat-network
    profiles: [ "kafka", "all", "auth", "user", "chat", "notification", "logging", "infra" ]
    healthcheck:
      test: [ "CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 0" ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  # Redis Cluster (Simulating production setup)
  redis-node-1:
    image: redis:6-alpine
    command: redis-server /usr/local/etc/redis/redis.conf
    ports:
      - "6379:6379"
      - "16379:16379"
    volumes:
      - ./docker/config/redis/redis-node-1.conf:/usr/local/etc/redis/redis.conf
      - redis-node-1-data:/data
    networks:
      - chat-network
    profiles: [ "redis", "all" ]
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  redis-node-2:
    image: redis:6-alpine
    command: redis-server /usr/local/etc/redis/redis.conf
    ports:
      - "6380:6379"
      - "16380:16379"
    volumes:
      - ./docker/config/redis/redis-node-2.conf:/usr/local/etc/redis/redis.conf
      - redis-node-2-data:/data
    networks:
      - chat-network
    profiles: [ "redis", "all" ]
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  redis-node-3:
    image: redis:6-alpine
    command: redis-server /usr/local/etc/redis/redis.conf
    ports:
      - "6381:6379"
      - "16381:16379"
    volumes:
      - ./docker/config/redis/redis-node-3.conf:/usr/local/etc/redis/redis.conf
      - redis-node-3-data:/data
    networks:
      - chat-network
    profiles: [ "redis", "all" ]
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  redis-cluster-init:
    image: redis:6-alpine
    depends_on:
      redis-node-1:
        condition: service_healthy
      redis-node-2:
        condition: service_healthy
      redis-node-3:
        condition: service_healthy
    command: >
      sh -c "sleep 5 &&
             redis-cli --cluster create redis-node-1:6379 redis-node-2:6379 redis-node-3:6379 --cluster-yes"
    networks:
      - chat-network
    profiles: [ "redis", "all" ]

  # Loki (Log Storage)
  loki:
    image: grafana/loki:2.9.0
    ports:
      - "3100:3100"
    volumes:
      - loki-data:/loki
      - ./docker/config/loki/local-config.yaml:/etc/loki/local-config.yaml
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - chat-network
    profiles: [ "logging", "all" ]
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 256M

  # Grafana (Visualization)
  grafana:
    image: grafana/grafana:10.2.0
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-worldmap-panel
    volumes:
      - grafana-data:/var/lib/grafana
      - ./docker/config/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      loki:
        condition: service_healthy
    networks:
      - chat-network
    profiles: [ "logging", "all" ]
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

networks:
  chat-network:
    driver: bridge

volumes:
  postgres-data:
  mongo-data:
  kafka-data:
  zookeeper-data:
  redis-node-1-data:
  redis-node-2-data:
  redis-node-3-data:
  api-gateway-node-modules:
  auth-service-node-modules:
  user-service-node-modules:
  chat-service-node-modules:
  notification-service-node-modules:
  logging-service-node-modules:
  loki-data:
  grafana-data:
